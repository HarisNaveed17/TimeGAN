{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "tutorial_timegan.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarisNaveed17/TimeGAN/blob/master/tutorial_timegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vybrqja6MSqF",
        "outputId": "554adb78-8f35-4eff-cb3c-82687e02d291"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwhLnyXRMU8P",
        "outputId": "5e97c273-178d-4346-884a-4088e6f15a88"
      },
      "source": [
        "cd drive/MyDrive/FYP"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FYP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aab0HnK2MZgm",
        "outputId": "7583cf71-b955-4ed8-8dce-ddc0194b8478"
      },
      "source": [
        "!git clone https://github.com/HarisNaveed17/TimeGAN.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TimeGAN'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 163 (delta 63), reused 98 (delta 43), pack-reused 44\u001b[K\n",
            "Receiving objects: 100% (163/163), 2.08 MiB | 12.26 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8skAv2OzMhRh"
      },
      "source": [
        "cd TimeGAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTxjib46L-3J"
      },
      "source": [
        "# TimeGAN Tutorial\n",
        "\n",
        "## Time-series Generative Adversarial Networks\n",
        "\n",
        "- Paper: Jinsung Yoon, Daniel Jarrett, Mihaela van der Schaar, \"Time-series Generative Adversarial Networks,\" Neural Information Processing Systems (NeurIPS), 2019.\n",
        "\n",
        "- Paper link: https://papers.nips.cc/paper/8789-time-series-generative-adversarial-networks\n",
        "\n",
        "- Last updated Date: April 24th 2020\n",
        "\n",
        "- Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n",
        "\n",
        "This notebook describes the user-guide of a time-series synthetic data generation application using timeGAN framework. We use Stock, Energy, and Sine dataset as examples.\n",
        "\n",
        "### Prerequisite\n",
        "Clone https://github.com/jsyoon0823/timeGAN.git to the current directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuXj1h_KL-3R"
      },
      "source": [
        "## Necessary packages and functions call\n",
        "\n",
        "- timegan: Synthetic time-series data generation module\n",
        "- data_loading: 2 real datasets and 1 synthetic datasets loading and preprocessing\n",
        "- metrics: \n",
        "    - discriminative_metrics: classify real data from synthetic data\n",
        "    - predictive_metrics: train on synthetic, test on real\n",
        "    - visualization: PCA and tSNE analyses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haa7kELbL-3U"
      },
      "source": [
        "## Necessary packages\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 1. TimeGAN model\n",
        "from timegan import timegan\n",
        "# 2. Data loading\n",
        "from data_loading import real_data_loading, sine_data_generation\n",
        "from utils import denormalizer\n",
        "# 3. Metrics\n",
        "from metrics.discriminative_metrics import discriminative_score_metrics\n",
        "from metrics.predictive_metrics import predictive_score_metrics\n",
        "from metrics.visualization_metrics import visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHVe90iiL-3U"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "Load original dataset and preprocess the loaded data.\n",
        "\n",
        "- data_name: stock, energy, or sine\n",
        "- seq_len: sequence length of the time-series data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WGynKqML-3V",
        "outputId": "4f0dc77a-6c88-451a-e9ce-64b051e59c6d"
      },
      "source": [
        "## Data loading\n",
        "data_name = 'telecomm'\n",
        "seq_len = 24\n",
        "\n",
        "if data_name in ['stock', 'energy','telecomm']:\n",
        "  ori_data, dat_min, dat_max = real_data_loading(data_name, seq_len)\n",
        "elif data_name == 'sine':\n",
        "  # Set number of samples and its dimensions\n",
        "  no, dim = 10000, 5\n",
        "  ori_data = sine_data_generation(no, seq_len, dim)\n",
        "    \n",
        "print(data_name + ' dataset is ready.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mixed data: [array([[0.35897436, 0.13327607],\n",
            "       [0.35897436, 0.        ],\n",
            "       [0.17948718, 0.72874091]]), array([[0.17948718, 0.69245969],\n",
            "       [0.12820513, 0.84943882],\n",
            "       [0.12820513, 0.65494963]]), array([[0.02564103, 0.84664275],\n",
            "       [0.02564103, 0.8839505 ],\n",
            "       [0.02564103, 0.99999996]]), array([[0.99999999, 0.14796881],\n",
            "       [0.69230769, 0.29374782],\n",
            "       [0.69230769, 0.45012165]]), array([[0.07692308, 0.62791545],\n",
            "       [0.02564103, 0.84664275],\n",
            "       [0.02564103, 0.8839505 ]]), array([[0.07692308, 0.66972547],\n",
            "       [0.07692308, 0.62791545],\n",
            "       [0.02564103, 0.84664275]]), array([[0.69230769, 0.29374782],\n",
            "       [0.69230769, 0.45012165],\n",
            "       [0.69230769, 0.37906319]]), array([[0.02564103, 0.8839505 ],\n",
            "       [0.02564103, 0.99999996],\n",
            "       [0.        , 0.76300762]]), array([[0.07692308, 0.70128629],\n",
            "       [0.07692308, 0.66972547],\n",
            "       [0.07692308, 0.62791545]]), array([[0.12820513, 0.65494963],\n",
            "       [0.12820513, 0.80161169],\n",
            "       [0.07692308, 0.70128629]]), array([[0.12820513, 0.84943882],\n",
            "       [0.12820513, 0.65494963],\n",
            "       [0.12820513, 0.80161169]]), array([[0.99999999, 0.26670942],\n",
            "       [0.99999999, 0.32952468],\n",
            "       [0.99999999, 0.14796881]]), array([[0.        , 0.76300762],\n",
            "       [0.        , 0.70359642],\n",
            "       [0.        , 0.87447953]]), array([[0.17948718, 0.72874091],\n",
            "       [0.17948718, 0.63394877],\n",
            "       [0.17948718, 0.69245969]]), array([[0.17948718, 0.63394877],\n",
            "       [0.17948718, 0.69245969],\n",
            "       [0.12820513, 0.84943882]]), array([[0.02564103, 0.99999996],\n",
            "       [0.        , 0.76300762],\n",
            "       [0.        , 0.70359642]]), array([[0.12820513, 0.80161169],\n",
            "       [0.07692308, 0.70128629],\n",
            "       [0.07692308, 0.66972547]]), array([[0.35897436, 0.18132573],\n",
            "       [0.35897436, 0.13327607],\n",
            "       [0.35897436, 0.        ]]), array([[0.69230769, 0.45012165],\n",
            "       [0.69230769, 0.37906319],\n",
            "       [0.35897436, 0.18132573]]), array([[0.99999999, 0.32952468],\n",
            "       [0.99999999, 0.14796881],\n",
            "       [0.69230769, 0.29374782]]), array([[0.35897436, 0.        ],\n",
            "       [0.17948718, 0.72874091],\n",
            "       [0.17948718, 0.63394877]]), array([[0.69230769, 0.37906319],\n",
            "       [0.35897436, 0.18132573],\n",
            "       [0.35897436, 0.13327607]])]\n",
            "tester dataset is ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfS_whepL-3V"
      },
      "source": [
        "## Set network parameters\n",
        "\n",
        "TimeGAN network parameters should be optimized for different datasets.\n",
        "\n",
        "- module: gru, lstm, or lstmLN\n",
        "- hidden_dim: hidden dimensions\n",
        "- num_layer: number of layers\n",
        "- iteration: number of training iterations\n",
        "- batch_size: the number of samples in each batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cCvCuqfL-3V"
      },
      "source": [
        "## Newtork parameters\n",
        "parameters = dict()\n",
        "\n",
        "parameters['module'] = 'gru' \n",
        "parameters['hidden_dim'] = 24\n",
        "parameters['num_layer'] = 3\n",
        "parameters['iterations'] = 5000\n",
        "parameters['batch_size'] = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH170h6XL-3W"
      },
      "source": [
        "## Run TimeGAN for synthetic time-series data generation\n",
        "\n",
        "TimeGAN uses the original data and network parameters to return the generated synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_wpT_KlL-3W",
        "outputId": "f2186cef-c242-4895-c0e3-1bd6ff7b7876"
      },
      "source": [
        "# Run TimeGAN\n",
        "generated_data = timegan(ori_data, parameters)   \n",
        "print('Finish Synthetic Data Generation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Embedding Network Training\n",
            "step: 0/5000, e_loss: 0.3605\n",
            "step: 1000/5000, e_loss: 0.0788\n",
            "step: 2000/5000, e_loss: 0.0414\n",
            "step: 3000/5000, e_loss: 0.0303\n",
            "step: 4000/5000, e_loss: 0.0227\n",
            "Finish Embedding Network Training\n",
            "Start Training with Supervised Loss Only\n",
            "step: 0/5000, s_loss: 0.3179\n",
            "step: 1000/5000, s_loss: 0.1762\n",
            "step: 2000/5000, s_loss: 0.1197\n",
            "step: 3000/5000, s_loss: 0.1152\n",
            "step: 4000/5000, s_loss: 0.0987\n",
            "Finish Training with Supervised Loss Only\n",
            "Start Joint Training\n",
            "step: 0/5000, d_loss: 2.0645, g_loss_u: 0.7093, g_loss_s: 0.1236, g_loss_v: 0.4818, e_loss_t0: 0.0378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMXA5jvBL-3X"
      },
      "source": [
        "denorm_data = denormalizer(dat_max, dat_min, generated_data, columns=[['internet', 'tweets',\r\n",
        "                                                                            'coverage', 'conditions', 'From Milan',\r\n",
        "                                                                            'To Milan', 'strength', 'Days', 'Hours',\r\n",
        "                                                                            'dayofyear']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvNbY0JNPAp"
      },
      "source": [
        "denorm_data.to_csv('internet4259_gputest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwfvygiGL-3X"
      },
      "source": [
        "## Evaluate the generated data\n",
        "\n",
        "### 1. Discriminative score\n",
        "\n",
        "To evaluate the classification accuracy between original and synthetic data using post-hoc RNN network. The output is |classification accuracy - 0.5|.\n",
        "\n",
        "- metric_iteration: the number of iterations for metric computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvfUtDPyL-3X"
      },
      "source": [
        "metric_iteration = 5\n",
        "\n",
        "discriminative_score = list()\n",
        "for _ in range(metric_iteration):\n",
        "  temp_disc = discriminative_score_metrics(ori_data, generated_data)\n",
        "  discriminative_score.append(temp_disc)\n",
        "\n",
        "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIYo5oH3L-3Y"
      },
      "source": [
        "## Evaluate the generated data\n",
        "\n",
        "### 2. Predictive score\n",
        "\n",
        "To evaluate the prediction performance on train on synthetic, test on real setting. More specifically, we use Post-hoc RNN architecture to predict one-step ahead and report the performance in terms of MAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN7kscbPL-3Y"
      },
      "source": [
        "predictive_score = list()\n",
        "for tt in range(metric_iteration):\n",
        "  temp_pred = predictive_score_metrics(ori_data, generated_data)\n",
        "  predictive_score.append(temp_pred)   \n",
        "    \n",
        "print('Predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipiBIq9iL-3Y"
      },
      "source": [
        "## Evaluate the generated data\n",
        "\n",
        "### 3. Visualization\n",
        "\n",
        "We visualize the original and synthetic data distributions using PCA and tSNE analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNWjl35aL-3Y"
      },
      "source": [
        "visualization(ori_data, generated_data, 'pca')\n",
        "visualization(ori_data, generated_data, 'tsne')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}